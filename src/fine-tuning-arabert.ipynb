{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd \nimport numpy as np\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pylab import rcParams\nfrom matplotlib import rc\nimport joblib\n\nfrom transformers import AutoTokenizer, AutoModel\nimport torch\nfrom torch import nn,optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics.functional import f1\nimport pytorch_lightning as pl\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, classification_report\n\nfrom tqdm.auto import tqdm","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-03-14T12:59:04.185037Z","iopub.execute_input":"2022-03-14T12:59:04.185248Z","iopub.status.idle":"2022-03-14T12:59:04.193521Z","shell.execute_reply.started":"2022-03-14T12:59:04.185222Z","shell.execute_reply":"2022-03-14T12:59:04.192185Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"path_input = '../input/arabicdialect/arabic_dialects_clean.csv'\ndf = pd.read_csv(path_input, lineterminator='\\n')\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-03-14T12:59:04.195353Z","iopub.execute_input":"2022-03-14T12:59:04.19575Z","iopub.status.idle":"2022-03-14T12:59:08.286954Z","shell.execute_reply.started":"2022-03-14T12:59:04.195706Z","shell.execute_reply":"2022-03-14T12:59:08.286083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train, val = train_test_split(df[['dialect','clean_text']], test_size=0.1, random_state=42)\n\ntrain = train.rename(columns={'dialect':\"label\",'clean_text':\"text\"})\nval = val.rename(columns={'dialect':\"label\",'clean_text':\"text\"})\nlbl_enc = LabelEncoder()\ntrain.loc[:,\"label\"] = lbl_enc.fit_transform(train[\"label\"])\nval.loc[:,\"label\"] = lbl_enc.transform(val[\"label\"])\njoblib.dump(lbl_enc,\"label_encoder.pkl\")\ntrain.to_csv(\"train.csv\",index=False)\nval.to_csv(\"val.csv\",index=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T12:59:08.2884Z","iopub.execute_input":"2022-03-14T12:59:08.289617Z","iopub.status.idle":"2022-03-14T12:59:11.256553Z","shell.execute_reply.started":"2022-03-14T12:59:08.289547Z","shell.execute_reply":"2022-03-14T12:59:11.255522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lbl_enc.classes_\n{v: k for v, k in enumerate(lbl_enc.classes_)}","metadata":{"execution":{"iopub.status.busy":"2022-03-14T12:59:31.72705Z","iopub.execute_input":"2022-03-14T12:59:31.727706Z","iopub.status.idle":"2022-03-14T12:59:31.735792Z","shell.execute_reply.started":"2022-03-14T12:59:31.727666Z","shell.execute_reply":"2022-03-14T12:59:31.734874Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArabicDataset(Dataset):\n    def __init__(self,data,max_len,model_type=\"Mini\"):\n        super().__init__()\n        self.labels = data[\"label\"].values\n        self.texts = data[\"text\"].values\n        self.max_len = max_len\n        model = {\"Mini\": \"asafaya/bert-mini-arabic\",\n                \"Medium\": \"asafaya/bert-medium-arabic\",\n                \"Base\": \"asafaya/bert-base-arabic\",\n                \"Large\": \"asafaya/bert-large-arabic\"}\n        self.tokenizer = AutoTokenizer.from_pretrained(model[model_type])\n    \n    def __len__(self):\n        return len(self.texts)\n    \n    def __getitem__(self,idx):\n        text = \" \".join(self.texts[idx].split())\n        label = self.labels[idx]\n        inputs = self.tokenizer(text,padding='max_length',\n                                max_length=self.max_len,truncation=True,return_tensors=\"pt\")\n        #input_ids,token_type_ids,attention_mask\n        return {\n            \"inputs\":{\"input_ids\":inputs[\"input_ids\"][0],\n                      \"token_type_ids\":inputs[\"token_type_ids\"][0],\n                      \"attention_mask\":inputs[\"attention_mask\"][0],\n                     },\n            \"labels\": torch.tensor(label,dtype=torch.long) \n        }","metadata":{"execution":{"iopub.status.busy":"2022-03-14T12:10:22.809278Z","iopub.execute_input":"2022-03-14T12:10:22.809878Z","iopub.status.idle":"2022-03-14T12:10:22.824054Z","shell.execute_reply.started":"2022-03-14T12:10:22.809833Z","shell.execute_reply":"2022-03-14T12:10:22.82282Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class ArabicDataModule(pl.LightningDataModule):\n    def __init__(self,train_path,val_path,batch_size=12,max_len=100,model_type=\"Mini\"):\n        super().__init__()\n        self.train_path,self.val_path= train_path,val_path\n        self.batch_size = batch_size\n        self.max_len = max_len\n        self.model_type = model_type\n    \n    def setup(self,stage=None):\n        train = pd.read_csv(self.train_path)\n        val = pd.read_csv(self.val_path)\n        self.train_dataset = ArabicDataset(data=train,max_len=self.max_len,model_type=self.model_type)\n        self.val_dataset = ArabicDataset(data=val,max_len=self.max_len,model_type=self.model_type)\n    \n    def train_dataloader(self):\n        return DataLoader(self.train_dataset,batch_size=self.batch_size,shuffle=True)\n    \n    def val_dataloader(self):\n        return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False)\n    \n    def test_dataloader(self):\n        return DataLoader(self.val_dataset,batch_size=self.batch_size,shuffle=False)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T12:10:22.825702Z","iopub.execute_input":"2022-03-14T12:10:22.826804Z","iopub.status.idle":"2022-03-14T12:10:22.840783Z","shell.execute_reply.started":"2022-03-14T12:10:22.826755Z","shell.execute_reply":"2022-03-14T12:10:22.839802Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"n_classes = 18\nclass ArabicBertModel(pl.LightningModule):\n    def __init__(self,model_type=\"Mini\"):\n        super().__init__()\n        model = {\"Mini\": (\"asafaya/bert-mini-arabic\",256),\n                \"Medium\": (\"asafaya/bert-medium-arabic\",512),\n                \"Base\": (\"asafaya/bert-base-arabic\",768),\n                \"Large\": (\"asafaya/bert-large-arabic\",1024)}\n        self.bert_model = AutoModel.from_pretrained(model[model_type][0])\n        self.fc = nn.Linear(model[model_type][1],n_classes)\n    \n    def forward(self,inputs):\n        out = self.bert_model(**inputs)#inputs[\"input_ids\"],inputs[\"token_type_ids\"],inputs[\"attention_mask\"])\n        last_hidden_states = out[1]\n        out = self.fc(last_hidden_states)\n        return out\n    \n    def configure_optimizers(self):\n        return optim.AdamW(self.parameters(), lr=0.0001)\n    \n    def criterion(self,output,target):\n        return nn.CrossEntropyLoss()(output,target)\n    \n    #TODO: adding metrics\n    def training_step(self,batch,batch_idx):\n        x,y = batch[\"inputs\"],batch[\"labels\"]\n        out = self(x)\n        loss = self.criterion(out,y)\n        f1_score = f1(out, y, num_classes=n_classes, average='macro')\n        metrics = {\"train_f1\": f1_score, \"train_loss\": loss}\n        self.log_dict(metrics)\n        return loss\n    \n    def validation_step(self,batch,batch_idx):\n        x, y = batch[\"inputs\"],batch[\"labels\"]\n        out = self(x)\n        loss = self.criterion(out,y)\n        f1_score = f1(out, y, num_classes=n_classes, average='macro')\n        metrics = {\"val_f1\": f1_score, \"val_loss\": loss}\n        self.log_dict(metrics)\n        return metrics","metadata":{"execution":{"iopub.status.busy":"2022-03-14T12:10:22.842957Z","iopub.execute_input":"2022-03-14T12:10:22.844031Z","iopub.status.idle":"2022-03-14T12:10:22.860662Z","shell.execute_reply.started":"2022-03-14T12:10:22.843978Z","shell.execute_reply":"2022-03-14T12:10:22.859481Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# TODO: getting different models sizes results\nMODEL_TYPE = \"Medium\"\ndm = ArabicDataModule(train_path=\"./train.csv\",\n                val_path = \"./val.csv\",\n                batch_size=128, max_len=70, model_type=MODEL_TYPE)\n\nmodel = ArabicBertModel(model_type=MODEL_TYPE)\ntrainer = pl.Trainer(gpus=-1,max_epochs=15, default_root_dir='.')\ntrainer.fit(model,dm)","metadata":{"execution":{"iopub.status.busy":"2022-03-14T09:46:54.193331Z","iopub.execute_input":"2022-03-14T09:46:54.193663Z","iopub.status.idle":"2022-03-14T09:48:40.823147Z","shell.execute_reply.started":"2022-03-14T09:46:54.193621Z","shell.execute_reply":"2022-03-14T09:48:40.822362Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.save(model, 'arabert_arabic_dialect.pth')","metadata":{"execution":{"iopub.status.busy":"2022-03-14T00:34:07.288211Z","iopub.execute_input":"2022-03-14T00:34:07.288629Z","iopub.status.idle":"2022-03-14T00:34:08.822271Z","shell.execute_reply.started":"2022-03-14T00:34:07.288587Z","shell.execute_reply":"2022-03-14T00:34:08.821547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n# model = torch.load('../input/fine-tuning-arabert/arabert_arabic_dialect.pth',  map_location=device)\nmodel.to(device)\n\npreds = []\nreal_values = []\n\ntest_dataloader = dm.test_dataloader()\n\nprogress_bar = tqdm(range(len(test_dataloader)))\n\nmodel.eval()\nfor batch in test_dataloader:    \n    x,y = batch[\"inputs\"],batch[\"labels\"]\n    inp = {k: v.to(device) for k, v in x.items()}\n    \n    with torch.no_grad():\n        outputs = model(inp)\n\n    predictions = torch.argmax(outputs, dim=1)\n    \n    preds.extend(predictions)\n    real_values.extend(y)\n\n    progress_bar.update()\n    \npreds = torch.stack(preds).cpu()\nreal_values = torch.stack(real_values).cpu()\nprint(classification_report(real_values, preds, target_names=lbl_enc.classes_))","metadata":{"execution":{"iopub.status.busy":"2022-03-14T12:22:52.811257Z","iopub.execute_input":"2022-03-14T12:22:52.811715Z","iopub.status.idle":"2022-03-14T12:22:53.181225Z","shell.execute_reply.started":"2022-03-14T12:22:52.811665Z","shell.execute_reply":"2022-03-14T12:22:53.180064Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}